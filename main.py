# -*- coding: utf-8 -*-
"""Copy of model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/193fnJtBfIS4gfqjvQ2xDiVDeCm8vAfM4
"""

!python --version

!pip install torch torchvision

import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML

# Set random seed for reproducibility
manualSeed = 999
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)
torch.use_deterministic_algorithms(True) # Needed for reproducible results

!pip install matplotlib

#Hyperparameters etc.
#dataset directory
datasetdir = "./resource"

#Number of workers for dataloader
workers = 2

#Batch size during training
batch_size = 128

#Spatial size of training images. All images will be resized to this
#size using a transformer
img_size = 64

#Input channels
nc = 1

#z vector size
z_dim = 100

#Size of feature maps in discriminator (output channels)
ndf = 64

#Number of training epochs
num_epochs = 40

#Learning rate of optimizers
lr = 0.0002

#Beta1 hyperparameter for Adam optimizers
beta1 = 0.5

#Number of GPUs available
ngpu = 1

#data input and device selection

#create dataset
#MNIST dataset for mock testing
dataset = MNIST(root=datasetdir,
                     train=True,
                     download=True,
                           transform=transforms.Compose([
                               transforms.Resize(img_size),
                               transforms.CenterCrop(img_size),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5,), (0.5,))
                           ]))

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

real_batch = next(iter(dataloader))

#custom weights initialization called on ``netG`` and ``netD``
def weights_init(model):
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.02)

#Discriminator Code
class Discriminator(nn.Module):
    def __init__(self, channels, features_d):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            #Input: N * channels x 64 x 64
            nn.Conv2d(
                channels, features_d, kernel_size=4, stride=2, padding=1
            ), #34 x 34 pixel values
            nn.LeakyReLU(0.2),
            self._block(features_d, features_d*2, 4, 2, 1), # 16x16
            self._block(features_d*2, features_d*4, 4, 2, 1), # 8x8
            self._block(features_d*4, features_d*8, 4, 2, 1), # 4x4
            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0, bias=False), # 1x1 (also converts to a single channel)
            nn.Sigmoid()
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            #input is ``(nx) * 64 * 64``
            nn.Conv2d(
                in_channels,
                out_channels,
                kernel_size,
                stride,
                padding,
                bias=False
            ),
            nn.BatchNorm2d(out_channels), #not in the official docs
            nn.LeakyReLU(0.2)
        )

    def forward(self, input):
        return self.disc(input)

#Generator Code

class Generator(nn.Module):
    def __init__(self, z_dim, channels, features_g):
        super(Generator, self).__init__()
        self.gen = nn.Sequential(
            #input : N x z_dim x 1 x 1
            self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4
            self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8
            self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16
            self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32
            nn.ConvTranspose2d(
                features_g*2, channels, kernel_size=4, stride=2, padding=1, bias=False
            ),
            nn.Tanh() # normalizes range within [-1, 1]
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.ConvTranspose2d(
                in_channels,
                out_channels,
                kernel_size,
                stride,
                padding,
                bias=False
            ),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(True)
        )

    def forward(self, input):
        return self.gen(input)

#initialise generator and discriminator

gen = Generator(z_dim, nc, 8).to(device)
disc = Discriminator(nc, 8).to(device)
weights_init(gen)
weights_init(disc)

#Loss calculator
fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)

#establish real and fake labels
real_label = 1.
fake_label = 0.

#setup Adam optimiers for both G and D
optimizerG = optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerD = optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))

criterion = nn.BCELoss()

# Commented out IPython magic to ensure Python compatibility.
#Training loop

G_losses = []
D_losses = []
i = 0

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):
        disc.zero_grad()
        #Format batch
        real = data[0].to(device)
        b_size = real.size(0)
        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)

        noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)
        fake = gen(noise)

        #Train Discriminator maximize log(D(x)) + log(1 - D(G(z)))
        disc_real = disc(real).view(-1)
        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))
        disc_fake = disc(fake).view(-1)
        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))
        loss_disc = (loss_disc_real + loss_disc_fake) / 2
        disc.zero_grad()
        loss_disc.backward(retain_graph=True)
        optimizerD.step()

        #Train Generator maximize log(D(G(z))) or minimize log(1 - D(G(z)))
        output = disc(fake).view(-1)
        loss_gen = criterion(output, torch.ones_like(output))
        gen.zero_grad()
        loss_gen.backward()
        optimizerG.step()

        #Print losses
        if i % 100 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f'
#                   % (epoch, num_epochs, i, len(dataloader),
                     loss_disc, loss_gen))

            with torch.no_grad():
                fake = gen(fixed_noise)
                #take out (up to) 32 examples
                img_grid_real = vutils.make_grid(
                    real[:32], normalize=True
                )
                img_grid_fake = vutils.make_grid(
                    fake[:32], normalize=True
                )

                #Losses for plotting
                G_losses.append(loss_gen)
                D_losses.append(loss_disc)

#plotting for losses
G_losses = [loss.item() if torch.is_tensor(loss) else loss for loss in G_losses]
D_losses = [loss.item() if torch.is_tensor(loss) else loss for loss in D_losses]

plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

#plotting for images
plt.figure(figsize=(8, 8))
plt.title("Generated Images")
plt.axis("off")
plt.imshow(np.transpose(img_grid_fake, (1, 2, 0)))
plt.show()

import pandas as pd
import seaborn as sns
#plotting heatmap G_losses
batches_per_epoch = len(G_losses) // 40

G_matrix = np.array(G_losses).reshape(num_epochs, batches_per_epoch)
D_matrix = np.array(D_losses).reshape(num_epochs, batches_per_epoch)

# Put into DataFrame (columns = batches, rows = epochs)
df_G = pd.DataFrame(G_matrix)

# Compute correlation
corr = df_G.corr()

# Plot annotated heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="magma", cbar=True)
plt.title("Correlation Heatmap of Generator Losses (Batches)")
plt.show()

#plotting heatmap D_losses
# Put into DataFrame (columns = batches, rows = epochs)
df_D = pd.DataFrame(D_matrix)

# Compute correlation
corr = df_D.corr()

# Plot annotated heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="magma", cbar=True)
plt.title("Correlation Heatmap of Discriminator Losses (Batches)")
plt.show()

#error calculation

errors = np.abs(np.array(G_losses) - np.array(D_losses))

plt.figure(figsize=(10,5))
plt.plot(errors, label="|G - D| Error")
plt.xlabel("Iterations")
plt.ylabel("Error")
plt.title("Difference Between Generator and Discriminator Loss")
plt.legend()
plt.show()

#lstm hyper parameters
seq_len = 10
input_dim = 100
hidden_dim = 128
num_layers = 1

#implementing conditional DCGAN with lstm as input instead of vector noise
#currently only takes last layer of hidden state as input
class Generator(nn.Module):
  def __init__(self, z_dim, channels ,features_g, hidden_size):
    super(Generator, self).__init__()
    #encode lstm parameters
    self.lstm = nn.LSTM(input_size=z_dim,
                        hidden_size=hidden_size,
                        num_layers=1,
                        bias=True,
                        batch_first=True)

    self.gen = nn.Sequential(
          #input : N x hidden_size x 1 x 1
          self._block(hidden_size, features_g*16, 4, 1, 0), # N x f_g*16 x 4 x 4
          self._block(features_g*16, features_g*8, 4, 2, 1), # 8 x 8
          self._block(features_g*8, features_g*4, 4, 2, 1), # 16 x 16
          self._block(features_g*4, features_g*2, 4, 2, 1), # 32 x 32
          nn.ConvTranspose2d(
              features_g*2, channels, kernel_size=4, stride=2, padding=1, bias=False
          ),
          nn.Tanh() # normalizes range within [-1, 1]
      )

  def _block(self, in_channels, out_channels, kernel_size, stride, padding):
      return nn.Sequential(
          nn.ConvTranspose2d(
              in_channels,
              out_channels,
              kernel_size,
              stride,
              padding,
              bias=False
          ),
          nn.BatchNorm2d(out_channels),
          nn.ReLU(True)
      )

  def forward(self, z_seq):
    _, (h_n, _) = self.lstm(z_seq) #extract the hidden state from output
    #h0 and c0 will be zero
    h_last = h_n[-1] #last layer of hidden state

    h_last = h_last.unsqueeze(-1).unsqueeze(-1) #modify dimensions

    return self.gen(h_last)

gen = Generator(z_dim, nc, 8, hidden_dim).to(device)
disc = Discriminator(nc, 8).to(device)
weights_init(gen)
weights_init(disc)

#Loss calculator
fixed_seq = torch.randn(64, seq_len, z_dim, device=device)

#Initialze lstm
lstm = nn.LSTM(input_size=input_dim,
               hidden_size=hidden_dim,
               num_layers=num_layers,
               batch_first=True).to(device)

#establish real and fake labels
real_label = 1.
fake_label = 0.

#setup Adam optimiers for both G and D
optimizerG = optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerD = optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))

criterion = nn.BCELoss()

# Commented out IPython magic to ensure Python compatibility.
#Training loop for lstm hybrid model

G_losses = []
D_losses = []
i = 0

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):
        disc.zero_grad()
        #Format batch
        real = data[0].to(device)
        b_size = real.size(0)
        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)

        #noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)
        lstm_input = torch.randn((batch_size, seq_len, input_dim)).to(device)
        #lstm_output, _ = lstm(lstm_input)
        #z = lstm_output[:, -1, :].unsqueeze(-1).unsqueeze(-1)
        fake = gen(lstm_input)

        #Train Discriminator maximize log(D(x)) + log(1 - D(G(z)))
        disc_real = disc(real).view(-1)
        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))

        #train on fake images with LSTM output as vector input
        disc_fake = disc(fake).view(-1)
        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))
        loss_disc = (loss_disc_real + loss_disc_fake) / 2
        disc.zero_grad()
        loss_disc.backward(retain_graph=True)
        optimizerD.step()

        #Train Generator maximize log(D(G(z))) or minimize log(1 - D(G(z)))
        output = disc(fake).view(-1)
        loss_gen = criterion(output, torch.ones_like(output))
        gen.zero_grad()
        loss_gen.backward()
        optimizerG.step()

        #Print losses
        if i % 100 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f'
#                   % (epoch, num_epochs, i, len(dataloader),
                     loss_disc, loss_gen))

            with torch.no_grad():
                fake = gen(fixed_seq)
                #take out (up to) 32 examples
                img_grid_real = vutils.make_grid(
                    real[:32], normalize=True
                )
                img_grid_fake = vutils.make_grid(
                    fake[:32], normalize=True
                )

                #Losses for plotting
                G_losses.append(loss_gen)
                D_losses.append(loss_disc)

#error calculation for lstm

G_losses = [g.detach().cpu().item() for g in G_losses]
D_losses = [d.detach().cpu().item() for d in D_losses]

errors = np.abs(np.array(G_losses) - np.array(D_losses))

plt.figure(figsize=(10,5))
plt.plot(errors, label="|G - D| Error")
plt.xlabel("Iterations")
plt.ylabel("Error")
plt.title("Difference Between Generator and Discriminator Loss")
plt.legend()
plt.show()

#plotting for images
plt.figure(figsize=(8, 8))
plt.title("Generated Images")
plt.axis("off")
plt.imshow(np.transpose(img_grid_fake, (1, 2, 0)))
plt.show()

import pandas as pd
import seaborn as sns
#plotting heatmap G_losses for LSTM hybrid
batches_per_epoch = len(G_losses) // 40

G_matrix = np.array(G_losses).reshape(num_epochs, batches_per_epoch)
D_matrix = np.array(D_losses).reshape(num_epochs, batches_per_epoch)

# Put into DataFrame (columns = batches, rows = epochs)
df_G = pd.DataFrame(G_matrix)

# Compute correlation
corr = df_G.corr()

# Plot annotated heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="magma", cbar=True)
plt.title("Correlation Heatmap of Generator Losses (Batches) for LSTM hybrid")
plt.show()

#plotting heatmap D_losses for LSTM hybrid
# Put into DataFrame (columns = batches, rows = epochs)
df_D = pd.DataFrame(D_matrix)

# Compute correlation
corr = df_D.corr()

# Plot annotated heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="magma", cbar=True)
plt.title("Correlation Heatmap of Discriminator Losses (Batches) for LSTM hybrid")
plt.show()